{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is for logging the process in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim corpora and dictionary\n",
    "\n",
    "How to tokenize words and convert them to vectors along with their occurance in the document using doc2bow function for the Dictionary in corpora of gensim and how to use token2id to make 2d vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 0, 'interface': 1, 'computer': 2, 'survey': 3, 'of': 4, 'user': 5, 'system': 6, 'response': 7, 'time': 8, 'eps': 9, 'trees': 10, 'graph': 11, 'minors': 12}\n",
      "[(0, 2), (1, 2), (2, 1), (6, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "               \"A survey of user opinion of computer system response time\",\n",
    "               \"The EPS user interface management system\",\n",
    "               \"System and human system engineering testing of EPS\",\n",
    "               \"Relation of user perceived response time to error measurement\",\n",
    "               \"The generation of random binary unordered trees\",\n",
    "               \"The intersection graph of paths in trees\",\n",
    "               \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "               \"Graph minors A survey\"]\n",
    "\n",
    "stoplist = set('for a fo the and to in'.split())\n",
    "\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in documents]\n",
    "#print(texts)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]for text in texts]\n",
    "#collecting values which are repetitive more than once.\n",
    "\n",
    "from pprint import pprint\n",
    "#pprint(texts)\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "#To save the dictionary to dict file for further use of this document.\n",
    "#uncomment the below to save the dictionary to the drive.\n",
    "\n",
    "##dictionary.save('kathitest.dict')\n",
    "print(dictionary.token2id)\n",
    "\n",
    "new_doc = \"Human computer interface human system interface\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(0, 2), (1, 2), (2, 1), (6, 1)]\n",
    "In the above list the first part of the tuple is the id from the 2d vector and the second part is the occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 0, 'interface': 1, 'computer': 2, 'survey': 3, 'of': 4, 'user': 5, 'system': 6, 'response': 7, 'time': 8, 'eps': 9, 'trees': 10, 'graph': 11, 'minors': 12}\n",
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(1, 1), (5, 1), (6, 1), (9, 1)]\n",
      "[(0, 1), (4, 1), (6, 2), (9, 1)]\n",
      "[(4, 1), (5, 1), (7, 1), (8, 1)]\n",
      "[(4, 1), (10, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1), (12, 1)]\n",
      "[(3, 1), (11, 1), (12, 1)]\n",
      "['human', 'interface', 'computer']\n",
      "['survey', 'of', 'user', 'of', 'computer', 'system', 'response', 'time']\n",
      "['eps', 'user', 'interface', 'system']\n",
      "['system', 'human', 'system', 'of', 'eps']\n",
      "['of', 'user', 'response', 'time']\n",
      "['of', 'trees']\n",
      "['graph', 'of', 'trees']\n",
      "['graph', 'minors', 'of', 'trees']\n",
      "['graph', 'minors', 'survey']\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(dictionary.token2id, end=\"\\n\")\n",
    "for c in corpus:\n",
    "    print(c, end=\"\\n\")\n",
    "for text in texts:\n",
    "    print(text, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling corpus without consuming large RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x00000022706E87B8>\n"
     ]
    }
   ],
   "source": [
    "class MyCorpus(object):\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in open(\"mycorpus.txt\"):\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "            \n",
    "            \n",
    "corpus_memory_friendly = MyCorpus()\n",
    "\"\"\"This will return generator instead of the entire list,\n",
    "which we can iterate effectively with out getting to memorize the elements which are read.\"\"\"\n",
    "\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(1, 1), (4, 1), (5, 1), (8, 1)]\n",
      "[(0, 1), (5, 2), (8, 1)]\n",
      "[(4, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(3, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "#save the corpus to the drive.\n",
    "corpora.MmCorpus.serialize(\"mycorpus.mm\", corpus_memory_friendly)\n",
    "\n",
    "for vector in corpus_memory_friendly:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting bag of words from the corpus text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 16, 3, 35, 19, 24, 8]\n",
      "[1, 3, 4, 5, 7, 12, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41]\n",
      "Dictionary(12 unique tokens: ['human', 'interface', 'computer', 'survey', 'user']...)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from six import iteritems\n",
    "\n",
    "\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('mycorpus.txt'))\n",
    "\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "            if stopword in dictionary.token2id]\n",
    "\n",
    "print(stop_ids)\n",
    "\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "\n",
    "print(once_ids)\n",
    "\n",
    "dictionary.filter_tokens(stop_ids + once_ids)\n",
    "dictionary.compactify()\n",
    "print(dictionary)\n",
    "#saving in to a dictionary file.\n",
    "dictionary.save(\"mycorpus.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 0, 'interface': 1, 'computer': 2, 'survey': 3, 'of': 4, 'user': 5, 'system': 6, 'response': 7, 'time': 8, 'eps': 9, 'trees': 10, 'graph': 11, 'minors': 12}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "ka_new_document = \"Human computer interface.\"\n",
    "ka_new_vector = dictionary.doc2bow(ka_new_document.lower().split())\n",
    "print(ka_new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '.' full stop is not considered in converting to vectors.\n",
    "with out '.', the generated vector will be as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "ka_new_document = \"Human computer interface\"\n",
    "ka_new_vector = dictionary.doc2bow(ka_new_document.lower().split())\n",
    "print(ka_new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random numpy_matrix is:  [[5 8]\n",
      " [9 5]\n",
      " [0 0]\n",
      " [1 7]\n",
      " [6 9]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'number_of_corpus_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9115aa10aeb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The random numpy_matrix is: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumpy_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense2Corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnumpy_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus2dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_of_corpus_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'number_of_corpus_features' is not defined"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "numpy_matrix = np.random.randint(10, size=[5,2])  # random matrix as an example\n",
    "print(\"The random numpy_matrix is: \",numpy_matrix)\n",
    "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
    "numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=number_of_corpus_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparse matrix is : \n",
      "The corpus is:  <gensim.matutils.Sparse2Corpus object at 0x00000022703E9320>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "scipy_sparse_matrix = scipy.sparse.random(5,2)  # random sparse matrix as example\n",
    "print(\"The sparse matrix is :\",scipy_sparse_matrix)\n",
    "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
    "print(\"The corpus is: \", corpus)\n",
    "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)\n",
    "print(scipy_csc_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corpus conversion using numpy and scipy.sparse random generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 0, 'interface': 1, 'computer': 2, 'survey': 3, 'user': 4, 'system': 5, 'response': 6, 'time': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n",
      "[(0, 1.0), (1, 1.0), (2, 1.0)]\n",
      "[(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(1, 1.0), (4, 1.0), (5, 1.0), (8, 1.0)]\n",
      "[(0, 1.0), (5, 2.0), (8, 1.0)]\n",
      "[(4, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(9, 1.0)]\n",
      "[(9, 1.0), (10, 1.0)]\n",
      "[(9, 1.0), (10, 1.0), (11, 1.0)]\n",
      "[(3, 1.0), (10, 1.0), (11, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "ka_dict = corpora.Dictionary.load(\"mycorpus.dict\")\n",
    "ka_corpus = corpora.MmCorpus(\"mycorpus.mm\")\n",
    "print(ka_dict.token2id, end=\"\\n\")\n",
    "for ka_corpora in ka_corpus:\n",
    "    print(ka_corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above is the way to load the corpus and the dictionary ids from the drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus loaded in the 'ka_corpus' is the generator, which then looped to get the individual vectors. The occurance is printed in float values.\n",
    "In the below the code the generator is retured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "print(ka_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The models in gensim has TfidfModel function.\n",
    "tfidf is treated as a read-only object that can be used to convert any vector from the old representation (bag-of-words integer counts) to the new representation (TfIdf real-valued weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(ka_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "test_vec = [(0,1),(1,1)]\n",
    "print(tfidf[test_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(2, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.3244870206138555), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.44424552527467476)]\n",
      "[(1, 0.5710059809418182), (4, 0.4170757362022777), (5, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(4, 0.45889394536615247), (6, 0.6282580468670046), (7, 0.6282580468670046)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(3, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for ka_corpora in ka_corpus:\n",
    "    print(tfidf[ka_corpora])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of vectors to the realistic values could be done either using the above code or using the below by applying to the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(2, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.3244870206138555), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.44424552527467476)]\n",
      "[(1, 0.5710059809418182), (4, 0.4170757362022777), (5, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(4, 0.45889394536615247), (6, 0.6282580468670046), (7, 0.6282580468670046)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(3, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "transformed_vectors = tfidf[ka_corpus]\n",
    "for vector in transformed_vectors:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
